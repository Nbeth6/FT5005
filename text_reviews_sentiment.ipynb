{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8b06a6c",
   "metadata": {},
   "source": [
    "# Reviews Sentiment\n",
    "\n",
    "For: Pao Pao\n",
    "\n",
    "The reviews are given as locations across all dates. Therefore, the two main complexities here are. \n",
    "\n",
    "1. We need to link the location to the company. This should be difficult.\n",
    "2. We will need to accumulate this up to a quarter level. This should be relatively easy.\n",
    "\n",
    "In the very basic form we basically want the output to be a csv file in the format below. (ideally order by quarter_year then by ticker but doesn't matter). `news_sentiment` should be values between 0 to 1 where the value vaguely represents the probability of a positive sentiment. Or -1 to 1 where -1 is neg and 1 is pos. This depends on you but *make it clear with a markdown at the end.*\n",
    "\n",
    "\n",
    "| ticker | quarter_year  | reviews_sentiment |\n",
    "|--------|---------------|-------------------|\n",
    "| BAC    | Q1 2001       | 0.2               |\n",
    "| JPM    | Q1 2001       | 0.67              |\n",
    "| WFC    | Q1 2001       | 0.97              |\n",
    "\n",
    "\n",
    "Of course some averaging will be needed so to prevent data loss, you could have multiple columns representing upper quartile sentiment, mean sentiment lower quartile sentiment for example. Ideally, you should have 2 output files; 1 for revenue and 1 for CAR.\n",
    "\n",
    "The main difference between reviews and the other 2 text data is reviews are not finance based so a model like FinBERT is not suitable. Perhaps, GPT 0-shot classification might work better.\n",
    "\n",
    "Be creative!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f9718f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "406f8122",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_data = pd.read_csv(\"data/text/reviews/extracted_reviews_24032025.csv\")\n",
    "reviews_data_2 = pd.read_csv(\"data/text/reviews/detailed_reviews_fix.csv\")\n",
    "reviews_data = pd.concat([reviews_data, reviews_data_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40536027",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing_reviews(text):\n",
    "    \"\"\"Write the text preprocessing function here. This should work through the `df.apply()` function\"\"\"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcd49f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analysis_reviews(reviews_data: pd.DataFrame):\n",
    "    \"\"\"This function should take in the news data and output the final csv file dataframe\"\"\"\n",
    "    output_data = reviews_data.copy()\n",
    "    return output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1a7832",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
